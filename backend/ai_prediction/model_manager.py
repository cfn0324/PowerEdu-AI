#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ¨¡å‹ç®¡ç†å™¨ - ç®¡ç†å¤šç§æœºå™¨å­¦ä¹ æ¨¡å‹
"""

import numpy as np
import joblib
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

try:
    from xgboost import XGBRegressor
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

class ModelManager:
    """æœºå™¨å­¦ä¹ æ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨"""
        self.models = {}
        self.performance = {}
        self.best_model_name = None
        self.is_trained = False
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._init_models()
    
    def _init_models(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹"""
        """åˆå§‹åŒ–æœºå™¨å­¦ä¹ æ¨¡å‹"""
        
        # çº¿æ€§å›å½’
        self.models['LinearRegression'] = LinearRegression()
        
        # éšæœºæ£®æ—
        self.models['RandomForest'] = RandomForestRegressor(
            n_estimators=100,
            random_state=42,
            n_jobs=-1
        )
        
        # æ¢¯åº¦æå‡ - ä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°è®¾ç½®
        try:
            self.models['GradientBoosting'] = GradientBoostingRegressor(
                n_estimators=20,  # è¿›ä¸€æ­¥å‡å°‘ä¼°è®¡å™¨æ•°é‡
                max_depth=2,      # æ›´å°çš„æ ‘æ·±åº¦
                learning_rate=0.2, # ç¨é«˜çš„å­¦ä¹ ç‡ä»¥è¡¥å¿è¾ƒå°‘çš„ä¼°è®¡å™¨
                random_state=42,
                subsample=0.9,    # ç¨é«˜çš„å­é‡‡æ ·æ¯”ä¾‹
                min_samples_split=5,  # æœ€å°åˆ†å‰²æ ·æœ¬æ•°
                min_samples_leaf=3    # æœ€å°å¶å­æ ·æœ¬æ•°
            )

        except Exception as e:
            print(f"   âš ï¸ GradientBoosting åˆå§‹åŒ–å¤±è´¥: {e}")
            # å¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼Œä»æ¨¡å‹å­—å…¸ä¸­ç§»é™¤
            if 'GradientBoosting' in self.models:
                del self.models['GradientBoosting']
        
        # æ”¯æŒå‘é‡å›å½’ - ä½¿ç”¨æ›´å®‰å…¨çš„å‚æ•°
        try:
            self.models['SVR'] = SVR(
                kernel='rbf', 
                C=0.5,           # è¿›ä¸€æ­¥é™ä½æ­£åˆ™åŒ–å‚æ•°
                gamma='scale',   # ä½¿ç”¨è‡ªåŠ¨ç¼©æ”¾
                epsilon=0.2,     # æ›´å¤§çš„å®¹é”™èŒƒå›´
                cache_size=500,  # å¢åŠ ç¼“å­˜å¤§å°
                max_iter=1000    # é™åˆ¶æœ€å¤§è¿­ä»£æ¬¡æ•°
            )

        except Exception as e:
            print(f"   âš ï¸ SVR åˆå§‹åŒ–å¤±è´¥: {e}")
            # å¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼Œä»æ¨¡å‹å­—å…¸ä¸­ç§»é™¤
            if 'SVR' in self.models:
                del self.models['SVR']
        
        # XGBoost (å¦‚æœå¯ç”¨) - ä½¿ç”¨å…¼å®¹æ€§æ›´å¥½çš„å‚æ•°
        if XGBOOST_AVAILABLE:
            try:
                self.models['XGBoost'] = XGBRegressor(
                    n_estimators=20,      # å‡å°‘ä¼°è®¡å™¨æ•°é‡
                    max_depth=2,          # æ›´å°çš„æ ‘æ·±åº¦
                    learning_rate=0.2,    # ç¨é«˜çš„å­¦ä¹ ç‡
                    random_state=42,
                    subsample=0.9,        # å­é‡‡æ ·æ¯”ä¾‹
                    colsample_bytree=0.8, # ç‰¹å¾é‡‡æ ·æ¯”ä¾‹
                    reg_alpha=0.1,        # L1æ­£åˆ™åŒ–
                    reg_lambda=0.1,       # L2æ­£åˆ™åŒ–
                    objective='reg:squarederror',  # æ˜ç¡®æŒ‡å®šç›®æ ‡å‡½æ•°
                    eval_metric='rmse',   # è¯„ä¼°æŒ‡æ ‡
                    verbosity=0,          # å…³é—­è¯¦ç»†è¾“å‡º
                    n_jobs=1              # å•çº¿ç¨‹è¿è¡Œé¿å…å†²çª
                )

            except Exception as e:
                print(f"   âš ï¸ XGBoost åˆå§‹åŒ–å¤±è´¥: {e}")
                # å¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼Œä»æ¨¡å‹å­—å…¸ä¸­ç§»é™¤
                if 'XGBoost' in self.models:
                    del self.models['XGBoost']
        else:
            print("   âš ï¸ XGBoost ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install xgboost")
        

    
    def train_all_models(self, X_train, y_train, X_test, y_test):
        """è®­ç»ƒæ‰€æœ‰æ¨¡å‹
        
        Args:
            X_train: è®­ç»ƒç‰¹å¾
            y_train: è®­ç»ƒç›®æ ‡
            X_test: æµ‹è¯•ç‰¹å¾
            y_test: æµ‹è¯•ç›®æ ‡
        """

        
        for name, model in self.models.items():
            try:
                # è®­ç»ƒæ¨¡å‹
                model.fit(X_train, y_train)
                
                # é¢„æµ‹
                y_pred = model.predict(X_test)
                
                # è¯„ä¼°æ€§èƒ½
                mse = mean_squared_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)
                rmse = np.sqrt(mse)
                
                # è®¡ç®—MAEå’ŒMAPE
                mae = np.mean(np.abs(y_test - y_pred))
                mape = np.mean(np.abs((y_test - y_pred) / np.maximum(np.abs(y_test), 1e-8))) * 100
                
                self.performance[name] = {
                    'mse': mse,
                    'r2': r2,
                    'rmse': rmse,
                    'mae': mae,
                    'mape': mape,
                    'training_time': 0
                }
                

                
            except Exception as e:
                print(f"    âŒ {name} è®­ç»ƒå¤±è´¥: {e}")
                # ä»æ¨¡å‹å­—å…¸ä¸­ç§»é™¤å¤±è´¥çš„æ¨¡å‹
                if name in self.models:
                    try:
                        del self.models[name]

                    except:
                        pass
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        if self.performance:
            self.best_model_name = min(self.performance.keys(), 
                                     key=lambda x: self.performance[x]['mse'])
            print(f"ğŸ† æœ€ä½³æ¨¡å‹: {self.best_model_name}")
            self.is_trained = True
        else:
            print("âŒ æ‰€æœ‰æ¨¡å‹è®­ç»ƒå¤±è´¥")
    
    def train_core_models(self, X_train, y_train, X_test, y_test):
        """è®­ç»ƒæ ¸å¿ƒæ¨¡å‹ - å¿«é€Ÿç‰ˆæœ¬ï¼Œåªè®­ç»ƒå…³é”®æ¨¡å‹
        
        Args:
            X_train: è®­ç»ƒç‰¹å¾
            y_train: è®­ç»ƒç›®æ ‡
            X_test: æµ‹è¯•ç‰¹å¾
            y_test: æµ‹è¯•ç›®æ ‡
        """
        print("ğŸš€ å¿«é€Ÿè®­ç»ƒæ ¸å¿ƒæ¨¡å‹...")
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºçš„æ¨¡å‹åˆ—è¡¨
        model_priority = [
            'LinearRegression',    # æœ€ç¨³å®š
            'RandomForest',        # é€šå¸¸å¾ˆå¯é 
            'GradientBoosting',    # å¯èƒ½æœ‰é—®é¢˜çš„æ¨¡å‹
            'SVR',                 # å¯èƒ½æœ‰é—®é¢˜çš„æ¨¡å‹
            'XGBoost'              # å¯èƒ½æœ‰é—®é¢˜çš„æ¨¡å‹
        ]
        
        successful_models = []
        
        for name in model_priority:
            if name in self.models:
                print(f"  è®­ç»ƒ {name}...")
                try:
                    model = self.models[name]
                    
                    # è®­ç»ƒæ¨¡å‹
                    model.fit(X_train, y_train)
                    
                    # é¢„æµ‹
                    y_pred = model.predict(X_test)
                    
                    # éªŒè¯é¢„æµ‹ç»“æœ
                    if np.any(np.isnan(y_pred)) or np.any(np.isinf(y_pred)):
                        raise ValueError("é¢„æµ‹ç»“æœåŒ…å«NaNæˆ–æ— ç©·å€¼")
                    
                    # è¯„ä¼°æ€§èƒ½
                    mse = mean_squared_error(y_test, y_pred)
                    r2 = r2_score(y_test, y_pred)
                    rmse = np.sqrt(mse)
                    
                    # è®¡ç®—MAEå’ŒMAPE
                    mae = np.mean(np.abs(y_test - y_pred))
                    mape = np.mean(np.abs((y_test - y_pred) / np.maximum(np.abs(y_test), 1e-8))) * 100
                    
                    # éªŒè¯æ€§èƒ½æŒ‡æ ‡
                    if np.isnan(mse) or np.isnan(r2) or mse < 0:
                        raise ValueError("æ€§èƒ½æŒ‡æ ‡å¼‚å¸¸")
                    
                    self.performance[name] = {
                        'mse': mse,
                        'r2': r2,
                        'rmse': rmse,
                        'mae': mae,
                        'mape': mape,
                        'training_time': 0  # å¯ä»¥åç»­æ·»åŠ è®¡æ—¶åŠŸèƒ½
                    }
                    
                    successful_models.append(name)
                    print(f"    âœ… {name}: MSE={mse:.6f}, RÂ²={r2:.6f}")
                    
                except Exception as e:
                    print(f"    âŒ {name} è®­ç»ƒå¤±è´¥: {e}")
                    # ä»æ¨¡å‹å­—å…¸ä¸­ç§»é™¤å¤±è´¥çš„æ¨¡å‹
                    if name in self.models:
                        try:
                            del self.models[name]
                            print(f"    ğŸ—‘ï¸ å·²ç§»é™¤æ•…éšœæ¨¡å‹: {name}")
                        except:
                            pass
                    continue
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æˆåŠŸçš„æ¨¡å‹
        if successful_models:
            # é€‰æ‹©æœ€ä½³æ¨¡å‹
            self.best_model_name = min(self.performance.keys(), 
                                     key=lambda k: self.performance[k]['mse'])
            print(f"âœ… è®­ç»ƒå®Œæˆï¼ŒæˆåŠŸæ¨¡å‹: {successful_models}")
            print(f"ğŸ† æœ€ä½³æ¨¡å‹: {self.best_model_name}")
            self.is_trained = True
        else:
            print("âŒ æ‰€æœ‰æ¨¡å‹è®­ç»ƒå¤±è´¥")
            self.is_trained = False
        
        return self.is_trained

    def predict(self, X):
        """ä½¿ç”¨æœ€ä½³æ¨¡å‹è¿›è¡Œé¢„æµ‹
        
        Args:
            X: è¾“å…¥ç‰¹å¾
            
        Returns:
            numpy.ndarray: é¢„æµ‹ç»“æœ
        """
        if not self.is_trained:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨train_all_models")
        
        if self.best_model_name is None:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒæ¨¡å‹")
        
        best_model = self.models[self.best_model_name]
        return best_model.predict(X)
    
    def predict_with_model(self, X, model_name):
        """ä½¿ç”¨æŒ‡å®šæ¨¡å‹è¿›è¡Œé¢„æµ‹
        
        Args:
            X: è¾“å…¥ç‰¹å¾
            model_name: æ¨¡å‹åç§°
            
        Returns:
            numpy.ndarray: é¢„æµ‹ç»“æœ
        """
        if model_name not in self.models:
            raise ValueError(f"æ¨¡å‹ {model_name} ä¸å­˜åœ¨")
        
        return self.models[model_name].predict(X)
    
    def get_model_performance(self):
        """è·å–æ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½æŒ‡æ ‡"""
        return self.performance.copy()
    
    def get_best_model_name(self):
        """è·å–æœ€ä½³æ¨¡å‹åç§°"""
        return self.best_model_name
    
    def get_available_models(self):
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        return list(self.models.keys())
    
    def save_models(self, filepath='models.pkl'):
        """ä¿å­˜æ¨¡å‹åˆ°æ–‡ä»¶
        
        Args:
            filepath: ä¿å­˜è·¯å¾„
        """
        if not self.is_trained:
            print("âŒ æ¨¡å‹æœªè®­ç»ƒï¼Œæ— æ³•ä¿å­˜")
            return False
        
        try:
            model_data = {
                'models': self.models,
                'performance': self.performance,
                'best_model_name': self.best_model_name,
                'is_trained': self.is_trained
            }
            joblib.dump(model_data, filepath)
            print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {filepath}")
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def load_models(self, filepath='models.pkl'):
        """ä»æ–‡ä»¶åŠ è½½æ¨¡å‹
        
        Args:
            filepath: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: åŠ è½½æ˜¯å¦æˆåŠŸ
        """
        try:
            model_data = joblib.load(filepath)
            self.models = model_data['models']
            self.performance = model_data['performance']
            self.best_model_name = model_data['best_model_name']
            self.is_trained = model_data['is_trained']
            print(f"ğŸ“‚ æ¨¡å‹å·²ä» {filepath} åŠ è½½")
            return True
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def get_model_comparison(self):
        """è·å–æ¨¡å‹æ€§èƒ½å¯¹æ¯”æ•°æ®ï¼ŒæŒ‰RÂ²åˆ†æ•°æ’åº
        
        Returns:
            list: æ’åºåçš„æ¨¡å‹æ€§èƒ½å¯¹æ¯”æ•°æ®
        """
        if not self.performance:
            return []
        
        comparison_data = []
        for model_name, metrics in self.performance.items():
            # è®¡ç®—é¢å¤–çš„æŒ‡æ ‡
            mae = metrics.get('mae', metrics.get('rmse', 0) * 0.8)  # å¦‚æœæ²¡æœ‰MAEï¼Œç”¨RMSEä¼°ç®—
            mape = metrics.get('mape', abs(1 - metrics.get('r2', 0)) * 100)  # å¦‚æœæ²¡æœ‰MAPEï¼Œç”¨RÂ²ä¼°ç®—
            
            comparison_data.append({
                'model': model_name,
                'r2': metrics.get('r2', 0),
                'rmse': metrics.get('rmse', 0),
                'mae': mae,
                'mape': mape,
                'mse': metrics.get('mse', 0),
                'training_time': metrics.get('training_time', 0)
            })
        
        # æŒ‰RÂ²åˆ†æ•°é™åºæ’åº
        comparison_data.sort(key=lambda x: x['r2'], reverse=True)
        
        return comparison_data

    def summary(self):
        """æ‰“å°æ¨¡å‹ç®¡ç†å™¨æ‘˜è¦"""
        print("ğŸ“‹ æ¨¡å‹ç®¡ç†å™¨æ‘˜è¦:")
        print(f"  - å¯ç”¨æ¨¡å‹: {len(self.models)}")
        print(f"  - æ¨¡å‹åˆ—è¡¨: {', '.join(self.models.keys())}")
        print(f"  - è®­ç»ƒçŠ¶æ€: {'å·²è®­ç»ƒ' if self.is_trained else 'æœªè®­ç»ƒ'}")
        print(f"  - æœ€ä½³æ¨¡å‹: {self.best_model_name or 'æœªç¡®å®š'}")
        
        if self.performance:
            print("  - æ€§èƒ½æŒ‡æ ‡:")
            for name, metrics in self.performance.items():
                print(f"    {name}: MSE={metrics['mse']:.6f}, RÂ²={metrics['r2']:.6f}")
