#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é¢„æµ‹åº”ç”¨è§†å›¾ - AI ç”µåŠ›è´Ÿè·é¢„æµ‹ API
"""

from ninja import Router
from django.contrib.auth.decorators import login_required
from django.utils.decorators import method_decorator
from django.views.decorators.csrf import csrf_exempt
from django.http import JsonResponse
from django.views.decorators.http import require_http_methods
import json
import sys
import os
import traceback
from datetime import datetime, timedelta
import pandas as pd
import numpy as np

# æ·»åŠ AIé¢„æµ‹æ¨¡å—è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
ai_prediction_path = os.path.join(current_dir, '../../ai_prediction')
sys.path.insert(0, ai_prediction_path)

# å…¨å±€å˜é‡å­˜å‚¨åˆå§‹åŒ–çš„ç»„ä»¶
_data_generator = None
_data_preprocessor = None
_model_manager = None
_predictor = None
_visualizer = None
_system_initialized = False

def check_system_ready():
    """æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å‡†å¤‡å°±ç»ªï¼Œå¹¶åœ¨å¿…è¦æ—¶æ›´æ–°çŠ¶æ€"""
    global _system_initialized, _model_manager
    
    # å¦‚æœæ¨¡å‹ç®¡ç†å™¨å­˜åœ¨ï¼Œæœ‰æ¨¡å‹ï¼Œä¸”å·²è®­ç»ƒï¼Œåˆ™è®¤ä¸ºç³»ç»Ÿå°±ç»ª
    if _model_manager and hasattr(_model_manager, 'models') and _model_manager.models:
        if _model_manager.is_trained and not _system_initialized:
            _system_initialized = True
            print("ğŸ”„ æ£€æµ‹åˆ°æ¨¡å‹å·²è®­ç»ƒï¼Œæ›´æ–°ç³»ç»ŸçŠ¶æ€ä¸ºå·²åˆå§‹åŒ–")
        return _model_manager.is_trained
    
    return _system_initialized

def initialize_ai_system():
    """åˆå§‹åŒ–AIé¢„æµ‹ç³»ç»Ÿ"""
    global _data_generator, _data_preprocessor, _model_manager, _predictor, _visualizer, _system_initialized
    
    if _system_initialized:
        print("âœ… AIç³»ç»Ÿå·²åˆå§‹åŒ–")
        return True
    
    try:
        print("ğŸš€ å¼€å§‹åˆå§‹åŒ–AIé¢„æµ‹ç³»ç»Ÿ...")
        
        # ç¡®ä¿AIé¢„æµ‹æ¨¡å—è·¯å¾„æ­£ç¡®æ·»åŠ 
        import sys
        import os
        current_dir = os.path.dirname(os.path.abspath(__file__))
        ai_prediction_path = os.path.join(current_dir, '../../ai_prediction')
        ai_prediction_path = os.path.abspath(ai_prediction_path)
        
        if ai_prediction_path not in sys.path:
            sys.path.insert(0, ai_prediction_path)
        
        # å¯¼å…¥AIæ¨¡å—
        from ai_prediction.data_generator import DataGenerator
        from ai_prediction.data_preprocessor import DataPreprocessor
        from ai_prediction.model_manager import ModelManager
        from ai_prediction.predictor import LoadPredictor
        from ai_prediction.visualizer import Visualizer
        
        # 1. åˆå§‹åŒ–æ•°æ®ç”Ÿæˆå™¨
        print("ğŸ“Š åˆå§‹åŒ–æ•°æ®ç”Ÿæˆå™¨...")
        _data_generator = DataGenerator()
        
        # 2. ç”Ÿæˆè®­ç»ƒæ•°æ® (ä½¿ç”¨è¾ƒå°‘çš„æ•°æ®é‡ä»¥åŠ å¿«é€Ÿåº¦)
        print("ğŸ“Š ç”Ÿæˆè®­ç»ƒæ•°æ®...")
        train_data = _data_generator.generate_training_data(days=14)  # 2å‘¨æ•°æ®
        print(f"âœ… ç”Ÿæˆæ•°æ®å®Œæˆï¼Œæ•°æ®é‡: {len(train_data)}")
        
        # 3. åˆå§‹åŒ–æ•°æ®é¢„å¤„ç†å™¨
        print("ğŸ”§ åˆå§‹åŒ–æ•°æ®é¢„å¤„ç†å™¨...")
        _data_preprocessor = DataPreprocessor()
        X_train, X_test, y_train, y_test = _data_preprocessor.fit_transform(train_data)
        print(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œè®­ç»ƒé›†: {X_train.shape}, æµ‹è¯•é›†: {X_test.shape}")
        
        # 4. åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨å¹¶è®­ç»ƒ
        print("ğŸ¤– åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨...")
        _model_manager = ModelManager()
        
        print("ğŸ“š å¼€å§‹è®­ç»ƒæ ¸å¿ƒæ¨¡å‹...")
        training_success = _model_manager.train_core_models(X_train, y_train, X_test, y_test)
        
        if not training_success:
            print("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
            return False
        
        print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæœ€ä½³æ¨¡å‹: {_model_manager.best_model_name}")
        
        # 5. åˆå§‹åŒ–é¢„æµ‹å™¨
        print("ğŸ”® åˆå§‹åŒ–é¢„æµ‹å™¨...")
        _predictor = LoadPredictor(_model_manager, _data_preprocessor)
        
        # 6. åˆå§‹åŒ–å¯è§†åŒ–å·¥å…·
        print("ğŸ“Š åˆå§‹åŒ–å¯è§†åŒ–å·¥å…·...")
        _visualizer = Visualizer()
        
        _system_initialized = True
        print("ğŸ‰ AIé¢„æµ‹ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
        print(f"   æœ€ä½³æ¨¡å‹: {_model_manager.best_model_name}")
        print(f"   å¯ç”¨æ¨¡å‹: {list(_model_manager.models.keys())}")
        return True
        
    except Exception as e:
        import traceback
        error_msg = f"âŒ AIé¢„æµ‹ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}"
        print(error_msg)
        print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        
        # é‡ç½®åˆå§‹åŒ–çŠ¶æ€
        _system_initialized = False
        return False
        
    except Exception as e:
        import traceback
        error_msg = f"âŒ AIé¢„æµ‹ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}"
        print(error_msg)
        print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        
        # é‡ç½®åˆå§‹åŒ–çŠ¶æ€
        _system_initialized = False
        return False

from .models import PredictionHistory, PredictionModel, ModelPerformance

router = Router()

@router.get("/")
def prediction_root(request):
    """AIé¢„æµ‹ç³»ç»Ÿæ ¹ç«¯ç‚¹"""
    return {
        "success": True,
        "message": "æ¬¢è¿ä½¿ç”¨AIç”µåŠ›è´Ÿè·é¢„æµ‹ç³»ç»Ÿ",
        "version": "1.0.0",
        "endpoints": {
            "system": {
                "status": "/api/prediction/system/status",
                "initialize": "/api/prediction/system/initialize"
            },
            "models": {
                "list": "/api/prediction/models",
                "performance": "/api/prediction/models/performance"
            },
            "prediction": {
                "single": "/api/prediction/predict/single",
                "batch": "/api/prediction/predict/batch",
                "day_ahead": "/api/prediction/predict/day-ahead",
                "uncertainty": "/api/prediction/predict/uncertainty"
            },
            "analysis": {
                "factors": "/api/prediction/analysis/factors",
                "error": "/api/prediction/analysis/error"
            },
            "data": {
                "history": "/api/prediction/history",
                "dashboard": "/api/prediction/dashboard",
                "generate": "/api/prediction/data/generate"
            }
        },
        "timestamp": datetime.now().isoformat()
    }

@router.get("/system/initialize")
def initialize_system(request):
    """åˆå§‹åŒ–AIé¢„æµ‹ç³»ç»Ÿ"""
    try:
        print("ğŸ”Œ æ”¶åˆ°AIç³»ç»Ÿåˆå§‹åŒ–è¯·æ±‚...")
        success = initialize_ai_system()
        if success:
            return {
                "success": True,
                "message": "AIé¢„æµ‹ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ",
                "timestamp": datetime.now().isoformat(),
                "data": {
                    "best_model": _model_manager.best_model_name if _model_manager else None,
                    "available_models": list(_model_manager.models.keys()) if _model_manager else [],
                    "training_status": _model_manager.is_trained if _model_manager else False
                }
            }
        else:
            return {
                "success": False,
                "message": "AIé¢„æµ‹ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯",
                "timestamp": datetime.now().isoformat(),
                "error": "æ¨¡å‹è®­ç»ƒæˆ–åˆå§‹åŒ–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯"
            }
    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        print(f"âŒ åˆå§‹åŒ–APIå¼‚å¸¸: {str(e)}")
        print(f"è¯¦ç»†é”™è¯¯: {error_trace}")
        return {
            "success": False,
            "message": "AIé¢„æµ‹ç³»ç»Ÿåˆå§‹åŒ–å¼‚å¸¸",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@router.get("/system/status")
def get_system_status(request):
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    global _model_manager
    
    # æ£€æŸ¥å¹¶æ›´æ–°ç³»ç»ŸçŠ¶æ€
    system_ready = check_system_ready()
    
    status = {
        "initialized": system_ready,
        "timestamp": datetime.now().isoformat()
    }
    
    # å¦‚æœæ¨¡å‹ç®¡ç†å™¨å­˜åœ¨ï¼Œæ·»åŠ æ¨¡å‹ä¿¡æ¯
    if _model_manager and hasattr(_model_manager, 'models'):
        status.update({
            "available_models": list(_model_manager.models.keys()),
            "best_model": _model_manager.best_model_name,
            "models_trained": _model_manager.is_trained
        })
    else:
        status.update({
            "available_models": [],
            "best_model": None,
            "models_trained": False
        })
    
    return {"success": True, "data": status}

@router.get("/debug/info")
def debug_info(request):
    """è°ƒè¯•ä¿¡æ¯ç«¯ç‚¹"""
    global _model_manager, _system_initialized, _data_generator, _data_preprocessor, _predictor, _visualizer
    
    debug_data = {
        "system_initialized": _system_initialized,
        "model_manager_exists": _model_manager is not None,
        "data_generator_exists": _data_generator is not None,
        "data_preprocessor_exists": _data_preprocessor is not None,
        "predictor_exists": _predictor is not None,
        "visualizer_exists": _visualizer is not None,
    }
    
    if _model_manager:
        debug_data.update({
            "models_count": len(_model_manager.models) if hasattr(_model_manager, 'models') else 0,
            "models_list": list(_model_manager.models.keys()) if hasattr(_model_manager, 'models') else [],
            "is_trained": _model_manager.is_trained if hasattr(_model_manager, 'is_trained') else False,
            "best_model": _model_manager.best_model_name if hasattr(_model_manager, 'best_model_name') else None,
            "performance_data": len(_model_manager.performance) if hasattr(_model_manager, 'performance') else 0
        })
    
    return {"success": True, "data": debug_data}

@router.get("/models")
def get_models(request):
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    global _model_manager
    
    # å¼ºåˆ¶æ€§æ£€æŸ¥ï¼šåªè¦æ¨¡å‹ç®¡ç†å™¨å­˜åœ¨ä¸”æœ‰æ¨¡å‹ï¼Œå°±è¿”å›æ¨¡å‹åˆ—è¡¨
    # ä¸å†ä¾èµ–åˆå§‹åŒ–çŠ¶æ€æ£€æŸ¥
    if _model_manager and hasattr(_model_manager, 'models'):
        if _model_manager.models:  # å¦‚æœæœ‰æ¨¡å‹
            try:
                models_info = []
                for name, model in _model_manager.models.items():
                    performance = _model_manager.performance.get(name, {})
                    models_info.append({
                        "name": name,
                        "type": type(model).__name__,
                        "is_best": name == _model_manager.best_model_name,
                        "performance": performance
                    })
                
                return {"success": True, "data": models_info}
            except Exception as e:
                return {"success": False, "error": f"æ„å»ºæ¨¡å‹ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}"}
        else:
            # æœ‰æ¨¡å‹ç®¡ç†å™¨ä½†æ²¡æœ‰è®­ç»ƒçš„æ¨¡å‹
            return {"success": False, "error": "æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨ç³»ç»Ÿåˆå§‹åŒ–"}
    
    # æ¨¡å‹ç®¡ç†å™¨ä¸å­˜åœ¨
    return {"success": False, "error": "ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ /system/initialize"}

@router.get("/models/performance")
def get_model_performance(request):
    """è·å–æ¨¡å‹æ€§èƒ½å¯¹æ¯”"""
    if not check_system_ready():
        return {"success": False, "error": "ç³»ç»Ÿæœªåˆå§‹åŒ–"}
    
    try:
        comparison = _model_manager.get_model_comparison()
        visualization = _visualizer.plot_model_comparison(_model_manager.performance)
        
        return {
            "success": True,
            "data": {
                "comparison": comparison,
                "visualization": visualization,
                "best_model": _model_manager.best_model_name
            }
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

@router.post("/predict/single")
def predict_single(request):
    """å•ç‚¹é¢„æµ‹"""
    if not check_system_ready():
        return {"success": False, "error": "ç³»ç»Ÿæœªåˆå§‹åŒ–"}
    
    try:
        data = json.loads(request.body)
        
        # å‚æ•°éªŒè¯
        required_fields = ['timestamp', 'temperature', 'humidity']
        for field in required_fields:
            if field not in data:
                return {"success": False, "error": f"ç¼ºå°‘å¿…éœ€å‚æ•°: {field}"}
        
        # æ‰§è¡Œé¢„æµ‹
        result = _predictor.predict_single_point(
            timestamp=data['timestamp'],
            temperature=data['temperature'],
            humidity=data['humidity'],
            wind_speed=data.get('wind_speed', 5.0),
            rainfall=data.get('rainfall', 0.0),
            model_name=data.get('model_name')
        )
        
        # ç”Ÿæˆå¯è§†åŒ–
        visualization = _visualizer.plot_single_prediction(result)
        
        # ä¿å­˜é¢„æµ‹å†å²
        if request.user.is_authenticated:
            PredictionHistory.objects.create(
                user=request.user,
                model=PredictionModel.objects.get_or_create(
                    name=result['model_used'],
                    defaults={'model_type': 'ml', 'description': 'æœºå™¨å­¦ä¹ æ¨¡å‹'}
                )[0],
                input_data=data,
                prediction_result=result,
                prediction_type='single'
            )
        
        return {
            "success": True,
            "data": {
                "prediction": result,
                "visualization": visualization
            }
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

@router.post("/predict/batch")
def predict_batch(request):
    """æ‰¹é‡é¢„æµ‹"""
    if not _system_initialized:
        return {"success": False, "error": "ç³»ç»Ÿæœªåˆå§‹åŒ–"}
    
    try:
        data = json.loads(request.body)
        
        if 'data_points' not in data:
            return {"success": False, "error": "ç¼ºå°‘å‚æ•°: data_points"}
        
        # æ‰§è¡Œæ‰¹é‡é¢„æµ‹
        results = _predictor.predict_batch(
            prediction_data=data['data_points'],
            model_name=data.get('model_name')
        )
        
        # ç”Ÿæˆå¯è§†åŒ–
        visualization = _visualizer.plot_batch_predictions(results)
        
        # ä¿å­˜é¢„æµ‹å†å²
        if request.user.is_authenticated:
            PredictionHistory.objects.create(
                user=request.user,
                model=PredictionModel.objects.get_or_create(
                    name=results[0]['model_used'],
                    defaults={'model_type': 'ml', 'description': 'æœºå™¨å­¦ä¹ æ¨¡å‹'}
                )[0],
                input_data=data,
                prediction_result={"results": results},
                prediction_type='batch'
            )
        
        return {
            "success": True,
            "data": {
                "predictions": results,
                "visualization": visualization,
                "summary": {
                    "total_points": len(results),
                    "model_used": results[0]['model_used'] if results else None
                }
            }
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

@router.post("/predict/day-ahead")
def predict_day_ahead(request):
    """æ—¥å‰é¢„æµ‹ï¼ˆ96ä¸ªæ—¶é—´ç‚¹ï¼‰"""
    if not _system_initialized:
        return {"success": False, "error": "ç³»ç»Ÿæœªåˆå§‹åŒ–"}
    
    try:
        data = json.loads(request.body)
        
        if 'target_date' not in data:
            return {"success": False, "error": "ç¼ºå°‘å‚æ•°: target_date"}
        
        # æ‰§è¡Œæ—¥å‰é¢„æµ‹
        result = _predictor.predict_day_ahead(
            target_date=data['target_date'],
            weather_forecast=data.get('weather_forecast'),
            model_name=data.get('model_name')
        )
        
        # ç”Ÿæˆå¯è§†åŒ–
        visualization = _visualizer.plot_day_ahead_prediction(result)
        
        # ä¿å­˜é¢„æµ‹å†å²
        if request.user.is_authenticated:
            PredictionHistory.objects.create(
                user=request.user,
                model=PredictionModel.objects.get_or_create(
                    name=result['model_used'],
                    defaults={'model_type': 'ml', 'description': 'æœºå™¨å­¦ä¹ æ¨¡å‹'}
                )[0],
                input_data=data,
                prediction_result=result,
                prediction_type='day_ahead'
            )
        
        return {
            "success": True,
            "data": {
                "prediction": result,
                "visualization": visualization
            }
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

@router.post("/predict/uncertainty")
def predict_with_uncertainty(request):
    """ä¸ç¡®å®šæ€§åˆ†æé¢„æµ‹"""
    if not _system_initialized:
        return {"success": False, "error": "ç³»ç»Ÿæœªåˆå§‹åŒ–"}
    
    try:
        data = json.loads(request.body)
        
        # æ‰§è¡Œä¸ç¡®å®šæ€§é¢„æµ‹
        result = _predictor.predict_with_uncertainty(
            input_data=data,
            n_samples=data.get('n_samples', 100)
        )
        
        return {"success": True, "data": result}
        
    except Exception as e:
        return {"success": False, "error": str(e)}

@router.post("/analysis/factors")
def analyze_prediction_factors(request):
    """é¢„æµ‹å› ç´ åˆ†æ"""
    if not _system_initialized:
        return {"success": False, "error": "ç³»ç»Ÿæœªåˆå§‹åŒ–"}
    
    try:
        data = json.loads(request.body)
        
        # åˆ†æé¢„æµ‹å› ç´ 
        analysis = _predictor.analyze_prediction_factors(
            prediction_result=data['prediction_result'],
            actual_load=data.get('actual_load')
        )
        
        return {"success": True, "data": analysis}
        
    except Exception as e:
        return {"success": False, "error": str(e)}

@router.post("/analysis/error")
def analyze_prediction_error(request):
    """é¢„æµ‹è¯¯å·®åˆ†æ"""
    if not _system_initialized:
        return {"success": False, "error": "ç³»ç»Ÿæœªåˆå§‹åŒ–"}
    
    try:
        data = json.loads(request.body)
        
        if 'predictions' not in data or 'actual_values' not in data:
            return {"success": False, "error": "ç¼ºå°‘å‚æ•°: predictions æˆ– actual_values"}
        
        # ç”Ÿæˆè¯¯å·®åˆ†æ
        analysis = _visualizer.plot_prediction_error_analysis(
            predictions=data['predictions'],
            actual_values=data['actual_values']
        )
        
        return {"success": True, "data": analysis}
        
    except Exception as e:
        return {"success": False, "error": str(e)}

@router.get("/history")
@method_decorator(login_required)
def get_prediction_history(request):
    """è·å–ç”¨æˆ·é¢„æµ‹å†å²"""
    try:
        histories = PredictionHistory.objects.filter(user=request.user).order_by('-created_at')[:50]
        
        history_data = []
        for history in histories:
            history_data.append({
                'id': history.id,
                'model_name': history.model.name,
                'prediction_type': history.prediction_type,
                'created_at': history.created_at.isoformat(),
                'input_summary': {
                    'timestamp': history.input_data.get('timestamp', 'N/A'),
                    'temperature': history.input_data.get('temperature', 'N/A')
                },
                'prediction_summary': {
                    'predicted_load': history.prediction_result.get('predicted_load', 'N/A')
                }
            })
        
        return {"success": True, "data": history_data}
        
    except Exception as e:
        return {"success": False, "error": str(e)}

@router.get("/dashboard")
def get_dashboard_data(request):
    """è·å–ä»ªè¡¨æ¿æ•°æ®"""
    if not _system_initialized:
        return {"success": False, "error": "ç³»ç»Ÿæœªåˆå§‹åŒ–"}
    
    try:
        # è·å–æ¨¡å‹æ€§èƒ½æ‘˜è¦
        performance_summary = _predictor.get_model_performance_summary()
        
        # ç”Ÿæˆç¤ºä¾‹é¢„æµ‹ï¼ˆæœ€è¿‘24å°æ—¶ï¼‰
        tomorrow = datetime.now().date() + timedelta(days=1)
        sample_prediction = _predictor.predict_day_ahead(tomorrow)
        
        # åˆ›å»ºä»ªè¡¨æ¿
        dashboard = _visualizer.create_dashboard_summary(
            prediction_results=sample_prediction,
            model_performance=_model_manager.performance
        )
        
        dashboard['system_info'] = {
            'initialized': _system_initialized,
            'total_models': len(_model_manager.models),
            'best_model': _model_manager.best_model_name,
            'last_updated': datetime.now().isoformat()
        }
        
        if request.user.is_authenticated:
            dashboard['user_stats'] = {
                'total_predictions': PredictionHistory.objects.filter(user=request.user).count(),
                'recent_predictions': PredictionHistory.objects.filter(
                    user=request.user,
                    created_at__gte=datetime.now() - timedelta(days=7)
                ).count()
            }
        
        return {"success": True, "data": dashboard}
        
    except Exception as e:
        return {"success": False, "error": str(e)}

@router.post("/data/generate")
def generate_sample_data(request):
    """ç”Ÿæˆç¤ºä¾‹æ•°æ®"""
    if not _system_initialized:
        return {"success": False, "error": "ç³»ç»Ÿæœªåˆå§‹åŒ–"}
    
    try:
        data = json.loads(request.body)
        days = data.get('days', 7)
        
        # ç”Ÿæˆç¤ºä¾‹æ•°æ®
        sample_data = _data_generator.generate_training_data(days=days)
        
        # è½¬æ¢ä¸ºJSONæ ¼å¼
        sample_data_json = sample_data.to_dict('records')
        
        return {
            "success": True,
            "data": {
                "sample_data": sample_data_json[:100],  # é™åˆ¶è¿”å›å‰100æ¡
                "total_records": len(sample_data_json),
                "columns": list(sample_data.columns)
            }
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}
